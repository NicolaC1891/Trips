import os

import faiss
from docx import Document
from sentence_transformers import SentenceTransformer
from sqlalchemy import Integer, Text, create_engine, select
from sqlalchemy.orm import Mapped, mapped_column, sessionmaker
from infrastructure.database.ORMmodels import Base
import numpy


def read_chunks_from_file():
    doc = Document('chunks.docx')
    chunk_list = []
    for paragraph in doc.paragraphs:
        text = paragraph.text.strip()
        if text:
            chunk_list.append(text)
    return chunk_list


def get_vectors_from_chunks(chunk_list):
    vectors = []
    model = SentenceTransformer('models/all-MiniLM-L6-v2')
    for chunk in chunk_list:
        embedding = model.encode(chunk, convert_to_numpy=True)
        vectors.append(embedding)
    vectors = numpy.array(vectors)
    vectors = vectors / numpy.linalg.norm(vectors, axis=1, keepdims=True)  # üîß –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    return vectors


class AIChunk(Base):
    __tablename__ = 'chunks'
    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)
    chunk_text: Mapped[str] = mapped_column(Text)


def write_chunks_to_db(session, chunk_list):
    chunk_objects = []
    for chunk in chunk_list:
        obj = AIChunk(chunk_text=chunk)
        chunk_objects.append(obj)
    session.add_all(chunk_objects)
    session.commit()   # –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤ AIChunk –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –≤ –∫–æ–¥–µ. –†–∞–±–æ—Ç–∞–µ—Ç –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å–µ—Å—Å–∏–∏.
    ids = [obj.id for obj in chunk_objects]
    return ids


def create_faiss_index(dimension, filename='faiss.index'):
    base_index = faiss.IndexFlatIP(dimension)  # üîÅ –±—ã–ª L2, —Å—Ç–∞–ª IP (inner product, –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞)
    index = faiss.IndexIDMap(base_index)  # –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –¥–æ–±–∞–≤–ª—è—Ç—å id
    faiss.write_index(index, filename)  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç–æ–π –∏–Ω–¥–µ–∫—Å –≤ —Ñ–∞–π–ª


def add_vectors_to_faiss(vectors, ids, path):
    index = faiss.read_index(path)                    # –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å –∏–∑ —Ñ–∞–π–ª–∞
    vectors_np = numpy.array(vectors).astype('float32')  # –ø—Ä–∏–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ –∫ numpy –º–∞—Å—Å–∏–≤—É
    ids_np = numpy.array(ids).astype('int64')            # –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è id
    index.add_with_ids(vectors_np, ids_np)            # –¥–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–∞ —Å id –≤–º–µ—Å—Ç–µ
    faiss.write_index(index, path)               # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–∞–π–ª


def do_everything(session):
    chunks = read_chunks_from_file()
    vectors = get_vectors_from_chunks(chunks)
    ids = write_chunks_to_db(session, chunks)
    path = 'faiss.index'
    dimension = vectors[0].shape[0]  # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ –∞—Ç—Ä–∏–±—É—Ç—É —Ñ–æ—Ä–º—ã –≤–µ–∫—Ç–æ—Ä–∞. –û–¥–∏–Ω–∞–∫–æ–≤–∞—è –¥–ª—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏. –°–º–µ–Ω–∏—Ç—Å—è –º–æ–¥–µ–ª—å - –ø–µ—Ä–µ–∑–∞–¥–∞—Ç—å
    if not os.path.exists(path):
        create_faiss_index(dimension, path)
    add_vectors_to_faiss(vectors, ids, path)


def show_me_chunks(session, request):
    model = SentenceTransformer('models/all-MiniLM-L6-v2')
    embedding = model.encode(request, convert_to_numpy=True).astype('float32')
    embedding = embedding / numpy.linalg.norm(embedding)  # üîß –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è

    index = faiss.read_index('faiss.index')

    k = 1
    D, I = index.search(embedding.reshape(1, -1), k)
    vector_ids = I[0].tolist()

    chunks = []
    for vector_id in vector_ids:
        statement = select(AIChunk).where(AIChunk.id == vector_id)
        result = session.execute(statement)
        chunk = result.scalar_one_or_none()
        if chunk is not None:
            chunks.append(chunk.chunk_text)
    return chunks


db_url = "sqlite:///../database/business_trips.db"
engine = create_engine(db_url)
SessionLocal = sessionmaker(bind=engine, expire_on_commit=False)
#do_everything(session=SessionLocal())

request = '–ö–æ–º—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –æ—Ç—á–µ—Ç –æ–± –∏—Ç–æ–≥–∞—Ö –∫–æ–º–∞–Ω–¥–∏—Ä–æ–≤–∫–∏?'
print(show_me_chunks(session=SessionLocal(), request=request))

request = '–ö—Ç–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–∏–∫–∞–∑ –æ –∫–æ–º–∞–Ω–¥–∏—Ä–æ–≤–∫–µ?'
print(show_me_chunks(session=SessionLocal(), request=request))